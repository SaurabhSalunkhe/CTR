{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "path=\"/FileStore/tables/sparkStreaming/\"\n",
    "\n",
    "# Creating a schema for our data. This will help us in processing the data faster since we are aware of the data type we\n",
    "# will be dealing with. \n",
    "\n",
    "adsSchema=StructType([\n",
    "  StructField(\"SearchID\",DoubleType(),True),\n",
    "  StructField(\"AdID\",DoubleType(),True),\n",
    "  StructField(\"Position\",DoubleType(),True),\n",
    "  StructField(\"ObjectType\",DoubleType(),True),\n",
    "  StructField(\"HistCTR\",DoubleType(),True),\n",
    "  StructField(\"IsClick\",DoubleType(),True),\n",
    "])\n",
    "\n",
    "\n",
    "# Static Dataframe containing all the files\n",
    "\n",
    "data=(\n",
    "    spark.\n",
    "        read.\n",
    "          schema(adsSchema)\n",
    "            .csv(path)\n",
    "      )\n",
    "\n",
    "# In order to use SQL functionalities, we need to create a table\n",
    "\n",
    "data.createOrReplaceTempView(\"TrainingData\")\n",
    "\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "streamInputDataFrame=(\n",
    "                    spark\n",
    "                      .readStream\n",
    "                      .schema(adsSchema)\n",
    "                      .option(\"maxFilesPerTrigger\",1)\n",
    "                      .csv(path)\n",
    "                      )\n",
    "# maxFilesPerTrigger ensures we have one file at a time\n",
    "\n",
    "streamCountDataFrame=(\n",
    "                      streamInputDataFrame\n",
    "                          .select(\"HistCTR\")\n",
    "                      )\n",
    "\n",
    "# To ensure that the streaming is actually working \n",
    "print(streamCountDataFrame.isStreaming)\n",
    "\n",
    "# This will check if streaming has started\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query=(\n",
    "  streamCountDataFrame\n",
    "        .writeStream\n",
    "        .format(\"memory\") \n",
    "        .queryName(\"HistCTRStream\")\n",
    "        .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from HistCTRStream limit 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "name": "ADS4_StreamingAnalysis",
  "notebookId": 403159077114881
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
